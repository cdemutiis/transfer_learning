{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training from scratch with a LeNet-like architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the CIFAR10 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 50000\n",
      "Number of testing examples = 10000\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 10\n"
     ]
    }
   ],
   "source": [
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "image_shape = X_train[0].shape\n",
    "n_classes = len(set(y_test)) \n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfCxcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f257aa8eb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "index = random.randint(0, n_train)\n",
    "image = X_train[index]\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5000.,  5000.,  5000.,  5000.,  5000.,  5000.,  5000.,  5000.,\n",
       "         5000.,  5000.]),\n",
       " array([ 0. ,  0.9,  1.8,  2.7,  3.6,  4.5,  5.4,  6.3,  7.2,  8.1,  9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f25943bbc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = -1 + 2*(X_train/255)\n",
    "X_test = -1 + 2*(X_test/255)\n",
    "plt.hist(y_train, bins=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x,keep_prob):    \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = 32x32x3. Output = 28x28x12.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 12), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(12))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # Pooling. Input = 28x28x12. Output = 14x14x12.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Layer 2: Convolutional. Output = 10x10x32.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 12, 32), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(32))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # Pooling. Input = 10x10x32. Output = 5x5x32.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    # Flatten. Input = 5x5x32. Output = 800.\n",
    "    fc0   = flatten(conv2)\n",
    "\n",
    "    # Layer 3: Fully Connected. Input = 800. Output = 120.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(800, 120), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(120))\n",
    "    fc2    = tf.matmul(fc0, fc2_W) + fc2_b\n",
    "    \n",
    "    # Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "    \n",
    "    # Dropout Layer \n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "    \n",
    "     # Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(84))\n",
    "    fc3    = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    # Activation.\n",
    "    fc3    = tf.nn.relu(fc3)\n",
    "    \n",
    "    # Dropout Layer \n",
    "    #fc3 = tf.nn.dropout(fc3, keep_prob)\n",
    "\n",
    "    # Layer 5: Fully Connected. Input = 84. Output = n_classes (10).\n",
    "    fc4_W  = tf.Variable(tf.truncated_normal(shape=(84, n_classes), mean = mu, stddev = sigma))\n",
    "    fc4_b  = tf.Variable(tf.zeros(n_classes))\n",
    "    logits = tf.matmul(fc3, fc4_W) + fc4_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training and evaluation operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Learning rate\n",
    "rate = 0.001\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, n_classes)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "logits = LeNet(x, keep_prob)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.371\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.451\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.502\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.526\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.544\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.549\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.567\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.585\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.597\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.598\n",
      "\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.608\n",
      "\n",
      "EPOCH 12 ...\n",
      "Validation Accuracy = 0.619\n",
      "\n",
      "EPOCH 13 ...\n",
      "Validation Accuracy = 0.626\n",
      "\n",
      "EPOCH 14 ...\n",
      "Validation Accuracy = 0.626\n",
      "\n",
      "EPOCH 15 ...\n",
      "Validation Accuracy = 0.635\n",
      "\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.629\n",
      "\n",
      "EPOCH 17 ...\n",
      "Validation Accuracy = 0.646\n",
      "\n",
      "EPOCH 18 ...\n",
      "Validation Accuracy = 0.641\n",
      "\n",
      "EPOCH 19 ...\n",
      "Validation Accuracy = 0.648\n",
      "\n",
      "EPOCH 20 ...\n",
      "Validation Accuracy = 0.649\n",
      "\n",
      "EPOCH 21 ...\n",
      "Validation Accuracy = 0.646\n",
      "\n",
      "EPOCH 22 ...\n",
      "Validation Accuracy = 0.653\n",
      "\n",
      "EPOCH 23 ...\n",
      "Validation Accuracy = 0.648\n",
      "\n",
      "EPOCH 24 ...\n",
      "Validation Accuracy = 0.642\n",
      "\n",
      "EPOCH 25 ...\n",
      "Validation Accuracy = 0.659\n",
      "\n",
      "EPOCH 26 ...\n",
      "Validation Accuracy = 0.658\n",
      "\n",
      "EPOCH 27 ...\n",
      "Validation Accuracy = 0.660\n",
      "\n",
      "EPOCH 28 ...\n",
      "Validation Accuracy = 0.660\n",
      "\n",
      "EPOCH 29 ...\n",
      "Validation Accuracy = 0.658\n",
      "\n",
      "EPOCH 30 ...\n",
      "Validation Accuracy = 0.665\n",
      "\n",
      "EPOCH 31 ...\n",
      "Validation Accuracy = 0.673\n",
      "\n",
      "EPOCH 32 ...\n",
      "Validation Accuracy = 0.659\n",
      "\n",
      "EPOCH 33 ...\n",
      "Validation Accuracy = 0.668\n",
      "\n",
      "EPOCH 34 ...\n",
      "Validation Accuracy = 0.672\n",
      "\n",
      "EPOCH 35 ...\n",
      "Validation Accuracy = 0.672\n",
      "\n",
      "EPOCH 36 ...\n",
      "Validation Accuracy = 0.669\n",
      "\n",
      "EPOCH 37 ...\n",
      "Validation Accuracy = 0.669\n",
      "\n",
      "EPOCH 38 ...\n",
      "Validation Accuracy = 0.668\n",
      "\n",
      "EPOCH 39 ...\n",
      "Validation Accuracy = 0.668\n",
      "\n",
      "EPOCH 40 ...\n",
      "Validation Accuracy = 0.671\n",
      "\n",
      "EPOCH 41 ...\n",
      "Validation Accuracy = 0.668\n",
      "\n",
      "EPOCH 42 ...\n",
      "Validation Accuracy = 0.678\n",
      "\n",
      "EPOCH 43 ...\n",
      "Validation Accuracy = 0.667\n",
      "\n",
      "EPOCH 44 ...\n",
      "Validation Accuracy = 0.670\n",
      "\n",
      "EPOCH 45 ...\n",
      "Validation Accuracy = 0.667\n",
      "\n",
      "EPOCH 46 ...\n",
      "Validation Accuracy = 0.667\n",
      "\n",
      "EPOCH 47 ...\n",
      "Validation Accuracy = 0.669\n",
      "\n",
      "EPOCH 48 ...\n",
      "Validation Accuracy = 0.669\n",
      "\n",
      "EPOCH 49 ...\n",
      "Validation Accuracy = 0.668\n",
      "\n",
      "EPOCH 50 ...\n",
      "Validation Accuracy = 0.662\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob:0.5})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.663\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
